{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Cancer Classification using Computerized Tomography\n",
    " Project developed by: **Eduardo Passos** [202205630](https://sigarra.up.pt/fcup/pt/fest_geral.cursos_list?pv_num_unico=202205630), **Pedro Fernandes** [202208347](https://sigarra.up.pt/fcup/pt/fest_geral.cursos_list?pv_num_unico=202208347) and **Rafael Pacheco** [202206258](https://sigarra.up.pt/fcup/pt/fest_geral.cursos_list?pv_num_unico=202206258)\n",
    "\n",
    "\n",
    "### Index {#index} #############################################\n",
    "1. [Project Introduction](#intro)\n",
    "2. [Data Understanding](#understand)\n",
    "3. [Feature Extraction](#ext)\n",
    "3.1. [Feature Extraction 2D]()\n",
    "3.2. [Feature Extraction 2D]()\n",
    "4. [Feature Selection and Dimensionality Reduction](#reduct)\n",
    "5. [Exploratory Data Analysis](#eda)\n",
    "6. [Models](#models)\n",
    "6.1. [Support Vector Machines](#svm)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Data Understanding {#understand}\n",
    "[Back to Index](#index)\n",
    "\n",
    "The [LIDC-IDRI](https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=1966254) dataset **contains the imaging data of the lungs** from over 1000 patients. This dataset is part of a collection of datasets provided by [**The Cancer Imaging Archive**](https://www.cancerimagingarchive.net/browse-collections/) for public research. The medical imaging data is provided in [**DICOM**](https://en.wikipedia.org/wiki/DICOM) (.dcm), and contains both image data, and associated metadata. It also contains the annotations of the medical professionals regarding the subject. \n",
    "\n",
    "The nodule annotations in the dataset **reflect the radiologist's evaluation** and include key information such as nodule size and malignancy rating (on a scale from 1-5). However, the **malignancy classification may vary based on each radiologist's judgment** and reasoning. What this means is that it introduces a level of subjectivity, making the classification potentially ambiguous and not always straightforward.\n",
    "\n",
    "The dataset contains noise, missing data, and file corruption. Some patients have incomplete annotations or no annotations at all, which complicates the training process since not all scans contain the necessary labels for nodule classification. \n",
    "\n",
    "In summary, not only many exceptions must be dealt with in the extratcion part, but also checked in the cleanup process.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction {#ext}\n",
    "[Back to Index](#index)\n",
    "\n",
    "### 3.1. Feature Extraction 2D\n",
    "[Back to Index](#index)\n",
    "\n",
    "This chapter explains the code behind the `feature_extraction_2D.py` script, created to find the nodule slices obtained using the `pylidc` library to extract and store radiomic and image features related to lung nodules. The processed data includes nodule images, masks, metadata, and radiomic features, all saved for further machine learning tasks.\n",
    "\n",
    "#### 1. Key Libraries\n",
    "\n",
    "- **pylidc**: Used to interact with the LIDC-IDRI dataset, including extracting scan and nodule information.\n",
    "- **SimpleITK**: Performs medical image processing tasks, such as converting images to and from arrays for manipulation.\n",
    "- **radiomics**: Extracts quantitative radiomic features from 3D medical images, like shape, texture, and intensity.\n",
    "- **scipy/ndimage**: Used for data augmentation via image rotation.\n",
    "- **pandas**: Organizes metadata in dataframes and saves them to CSV.\n",
    "\n",
    "#### 2. Configuration Settings\n",
    "[Back to Index](#index)\n",
    "\n",
    "The script reads parameters from a configuration file (`lung.conf`). These settings include:\n",
    "\n",
    "1. **Directories**:\n",
    "   - `LIDC_DICOM_PATH`: Location of the DICOM files.\n",
    "   - `MASK_PATH`: Where masks are saved.\n",
    "   - `IMAGE_PATH`: Where cropped and processed nodule images are stored.\n",
    "   - `META_PATH`: Location for saving metadata files.\n",
    "\n",
    "2. **Hyperparameters**:\n",
    "   - **mask_threshold**: Minimum pixel count for a mask to be considered valid.\n",
    "   - **confidence_level**: Used for consensus mask generation from annotations.\n",
    "   - **padding_size**: Padding around the nodule region during cropping.\n",
    "\n",
    "#### 3. Class: `MakeDataSet`\n",
    "\n",
    "This class handles the processing of each scan, extracting nodule-related data, generating masks, calculating features, and saving all information for later use.\n",
    "\n",
    "Before processing each scan, data quality is assessed based on:\n",
    "- The existence of slice values (`slice_zvals`) and DICOM images.\n",
    "- Consistency in slice thickness.\n",
    "- The number of slices and image availability.\n",
    "\n",
    "The malignancy of each nodule is calculated using the **median of annotations** provided by radiologists. Malignancy scores determine if a nodule is labeled as **cancerous** or **non-cancerous**. CT scans are normalized based on **Hounsfield Units (HU)** to focus on regions of interest. Values are clipped and rescaled to fit within a range of 0 to 1.\n",
    "\n",
    "The class uses the **Radiomics Feature Extractor** to compute a variety of 3D features from the normalized images and their corresponding masks. These features include shape, intensity, and texture metrics.\n",
    "\n",
    "#### 4. Nodule Processing\n",
    "\n",
    "For each patient, the script:\n",
    "1. Loads the full CT scan and normalizes it.\n",
    "2. Iterates through each detected nodule, performing the following tasks:\n",
    "   - Extracts a **consensus mask** based on the annotations.\n",
    "   - **Crops** the nodule area and mask.\n",
    "   - Saves the cropped image and mask to disk.\n",
    "   - **Augments** the data by rotating the images and masks in various angles around different axes.\n",
    "   - **Extracts radiomic features** from both the original and augmented images.\n",
    "   - **Stores metadata** about each nodule, including malignancy score and radiomic features.\n",
    "\n",
    "#### 5. Data Augmentation\n",
    "\n",
    "For each nodule, the script applies rotations to the cropped image and mask in the x, y, and z planes. These augmented images are saved with distinct file names, increasing the variety of data for training machine learning models.\n",
    "\n",
    "#### 6. Metadata and Output\n",
    "\n",
    "All extracted features and relevant metadata are saved to a **CSV file**. This metadata includes:\n",
    "\n",
    "- Patient ID\n",
    "- Nodule number\n",
    "- Original and mask image file names\n",
    "- Malignancy score\n",
    "- Radiomic features\n",
    "\n",
    "The CSV is finalized at the end of the processing, and can later be used to train models based on them.\n",
    "\n",
    "#### 7. Main Function\n",
    "\n",
    "The script processes a specified number of LIDC-IDRI scans (up to 10 in the default configuration). For each scan, it initializes the `MakeDataSet` class and calls the `process_scan()` method to handle all data extraction, augmentation, and saving tasks.\n",
    "\n",
    "---\n",
    "### 3.2. Feature Extraction 3D \n",
    "[Back to Index](#index)\n",
    "\n",
    "This chapter explains the code behind the `feature_extraction_3D.py` script, designed to extract features from the dataset. This script uses a combination of libraries for medical image processing, radiomic feature extraction, and deep learning-based feature extraction using a [CNN (ResNet-18 model)](https://medium.com/analytics-vidhya/resnet-understand-and-implement-from-scratch-d0eb9725e0db). Below is an in-depth explanation of the \"routines\" that constitute the process.\n",
    "\n",
    "\n",
    "#### 1) Key Libraries\n",
    "\n",
    "- **pylidc**: For the interaction with the LIDC-IDRI dataset.\n",
    "- **SimpleITK**: For medical image processing tasks.\n",
    "- **radiomics**: Provides various techniques to extract quantitative radiomic features from 3D medical imaging, like shape, texture, and intensity-based features.\n",
    "- **torch and monai**: Used to train the neural network for feature extraction. Specifically, `monai.networks.nets.ResNet18`, which provides a pre-trained ResNet-18 CNN model designed for medical imaging tasks.\n",
    "\n",
    "#### 2) Command-Line Argument Parsing: \n",
    "\n",
    "The `parse_arguments()` function uses Python's `argparse` library to parse command-line arguments, allowing for flexible and customizable script behavior. The **arguments defined** are the following:\n",
    "\n",
    "1. **`--output_dir`**: Specify the folder to save the extracted feature CSV files.\n",
    "   \n",
    "2. **`--log_file`**: Path to the file where the script will write all its logs and messages. \n",
    "\n",
    "3. **`--csv_file`** (Optional): Choose whether to save all features in a single CSV file or in 2, this is where you set the path. (individual CSVs are saved by default)\n",
    "\n",
    "4. **`--scan_limit`**: Control how many scans the script processes. If 0 or a negative number, it will process all available scans.\n",
    "\n",
    "5. **`--consensus_level`**: This sets the confidence level (between 0 and 1) for generating a consensus mask from multiple radiologist annotations.\n",
    "\n",
    "6. **`--num_workers`**: Number of worker threads for parallel processing. \n",
    "\n",
    "7. **`--cnn_feature_dim`**: Defines the size of the CNN feature vector to extract, with a default set at 128 dimensions.\n",
    "\n",
    "8. **`--model_path`**: Path to a pre-trained CNN model. If none is provided, the script will use a ResNet-18 model from the MONAI library as the fallback.\n",
    "\n",
    "Parsed arguments can be easily accessed throughout the script.\n",
    "\n",
    "\n",
    "#### 3) Resampling and HU Normalization\n",
    "\n",
    "To ensure reliability and standardization across scans, the 3D CT scans are resampled to a fixed voxel spacing using **trilinear interpolation**. This ensures that the scans from different machines or resolutions are brought to a consistent format.\n",
    "\n",
    "Additionally, Hounsfield Units (HU), which represent the density values in CT images, are normalized. This involves two main functions:\n",
    "\n",
    "- **`clamp_hounsfield_units()`**: Clamps HU values within a specific range (e.g., -1000 to 400) to focus on the regions of interest like lung tissue (excluding irrelevant areas like air or bones).\n",
    "- **`normalize_intensity()`**: Further scales the intensity values for consistent input into the neural network model.\n",
    "\n",
    "\n",
    "#### 4) Bounding Box Calculation: \n",
    "\n",
    "After preprocessing, the `get_bounding_box()` determines the **bounding box** for each nodule in the scan:\n",
    "\n",
    "- The **binary mask** representing the nodule is processed to find the smallest box that contains all `True` (or 1) values, which represent the nodule region.\n",
    "- This is crucial for reducing the amount of data being processed, focusing only on the nodule area instead of the entire scan.\n",
    "\n",
    "\n",
    "#### 5) Nodule Extraction and Resizing\n",
    "\n",
    "Once the bounding box is determined, the nodule is extracted from the original 3D scan. The extracted nodule is then resized to a consistent shape and size, making it ready for feature extraction. This is especially important for the CNN, which expects inputs of fixed dimensions.\n",
    "\n",
    "\n",
    "#### 6) Malignancy Evaluation\n",
    "\n",
    "Each nodule in the LIDC-IDRI dataset is annotated by multiple radiologists, and each provides a score for malignancy (among other characteristics). The **median score** of malignancy is used as a target label for training the model. This helps in creating a more robust and reliable training dataset by minimizing bias from individual radiologists' evaluations.\n",
    "\n",
    "\n",
    "#### 7) CNN-Based Feature Extraction: ResNet-18\n",
    "\n",
    "For deep learning-based feature extraction, a **ResNet-18 CNN model** is applied to each extracted nodule. ResNet-18 is a well-known architecture that introduces residual connections, enabling deeper networks to be trained efficiently.\n",
    "\n",
    "- The script uses a **pre-trained ResNet-18 model** (either provided via `--model_path` or by default from MONAI).\n",
    "- The model extracts **CNN features** of a predefined size (e.g., 128-dimensional), which are saved as part of the final feature set.\n",
    "\n",
    "\n",
    "#### 8) Radiomic Feature Extraction\n",
    "\n",
    "In addition to CNN-based features, the script also uses the **radiomics library** to extract traditional radiomic features from the nodules. These features include:\n",
    "\n",
    "- **Shape features**: Describing the geometric properties of the nodule (e.g., volume, elongation, flatness).\n",
    "- **Texture features**: Quantifying the patterns and variations in pixel intensity within the nodule.\n",
    "- **Intensity-based features**: Capturing the intensity distribution in the nodule region.\n",
    "\n",
    "\n",
    "#### 9) Feature Aggregation and Output\n",
    "\n",
    "Once both CNN and radiomic features are extracted, they are **aggregated into a final CSV file**. Each row in the CSV file represents a nodule, meaning each nodule is evaluated independently, and helps on the case of a patient having different nodules.\n",
    "\n",
    "This CSV file serves as the input for subsequent machine learning tasks.\n",
    "\n",
    "The script is designed to save separate CSV files for each nodule by default. However, an option is provided to save a single CSV file containing all features via the `--csv_file` argument.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection and Dimensionality Reduction {#reduct}\n",
    "[Back to Index](#index)\n",
    "\n",
    "There are 3 different \"types of data\" as a result of the scripts made for processing:\n",
    "- `meta_info_2d.csv`: contains the features for each slice individually, meaning the model will be trained in single slices, since the same nodule can have malignant slices and benign slices simultaneously;\n",
    "- `meta_info_3d.csv`: contains the 3D features extracted using the script mentioned in 3.2.\n",
    "- `cnn_features.csv`: contains the ResNet18 features also described above.\n",
    "\n",
    "To develop the models, the `meta_info_3d.csv` and `cnn_features.csv` can be merged using the `merge_csvs.py`, if they are created individually, when defining the script behaviour on the `feature_extraction_3d.py`.\n",
    "\n",
    "The dataset will be cleaned and the process explained in the `cleanup_2d.ipynb` and `cleanup_3d.ipynb`. To summarise the process in both scripts, we will:\n",
    "\n",
    "- Evaluate the missing values, outliers(X)\n",
    "- Perform a **Recursive Feature Extraction** to select the best features, so that the model training is easier to perform.\n",
    "- (...)\n",
    "\n",
    "After the scripts are ran, we are left with the `clean_2d.csv` and `clean_3d.csv` files, that will be used on the **Exploratory Data Analysis**."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis {#eda}\n",
    "[Back to Index](#index)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
