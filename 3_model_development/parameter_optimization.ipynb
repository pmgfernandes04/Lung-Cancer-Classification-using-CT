{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluating various models, we will now focus on enhancing their performance through parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we will start our tests by initializing a pandas DataFrame using the data from the `lidc_rfe50.csv` file. This file contains a combined set of radiomics and deep features after applying RFE to retain 50 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'../2_csv_manipulation/lidc_rfe50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will be using the binary transformation of the dataset (ambiguity removed) to quickly evaluate different parameters for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row size changed from 2626 to 1238 (lost 1388 rows).\n"
     ]
    }
   ],
   "source": [
    "# Removes ambiguous option\n",
    "df_rem = df.copy()\n",
    "before = df_rem.shape[0] # n_linhas antes\n",
    "\n",
    "mask = df_rem['is_cancer'] == 1\n",
    "df_rem = df_rem[~mask]\n",
    "after = df_rem.shape[0] # n_linhas depois\n",
    "\n",
    "df_rem['is_cancer'] = df_rem['is_cancer'].replace(2, 1)\n",
    "print(f\"Row size changed from {before} to {after} (lost {before-after} rows).\")\n",
    "\n",
    "X = df_rem.drop('is_cancer', axis=1)\n",
    "y = df_rem['is_cancer']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be utilizing SMOTE in our final report, hyperparameter tuning will be conducted after applying SMOTE (helps avoid majority class bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_sampler = SMOTE()\n",
    "X_train, y_train = smote_sampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used Grid Search for most of our models, ocasionally applying Randomized Search in the cases where the hyperparameter space could become complex, due to the nature of the model itself (Random Forest, XGBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This will help us efficiently combine all of them in the stacking method outlined in the final `report.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter=900)\n",
    "logistic_params = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "logistic_search = GridSearchCV(logistic_model, logistic_params, cv=5, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(class_weight='balanced')\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "rf_search = RandomizedSearchCV(rf_model, rf_params, cv=5, scoring='accuracy', n_jobs=-1, n_iter=50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "xgb_search = RandomizedSearchCV(xgb_model, xgb_params, cv=5, scoring='accuracy', n_jobs=-1, n_iter=50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='rbf')\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "svm_search = GridSearchCV(svm_model, svm_params, cv=5, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_params = {\n",
    "    'var_smoothing': np.logspace(-9, -1, 9)\n",
    "}\n",
    "gnb_search = GridSearchCV(gnb_model, gnb_params, cv=5, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Grid and Randomized Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters for Logistic Regression...\n",
      "Best parameters for Logistic Regression complete. [{'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}] model stored in dictionary.\n",
      "\n",
      "Testing parameters for Random Forest...\n",
      "Best parameters for Random Forest complete. [{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 20}] model stored in dictionary.\n",
      "\n",
      "Testing parameters for XGBoost...\n",
      "Best parameters for XGBoost complete. [{'subsample': 0.9, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 0.9}] model stored in dictionary.\n",
      "\n",
      "Testing parameters for SVM...\n",
      "Best parameters for SVM complete. [{'C': 10, 'gamma': 1, 'kernel': 'rbf'}] model stored in dictionary.\n",
      "\n",
      "Testing parameters for Gaussian Naive Bayes...\n",
      "Best parameters for Gaussian Naive Bayes complete. [{'var_smoothing': 1e-09}] model stored in dictionary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store best models\n",
    "best_models = {}\n",
    "\n",
    "# List of (model name, search object) tuples for easy iteration\n",
    "model_searches = [\n",
    "    (\"Logistic Regression\", logistic_search),\n",
    "    (\"Random Forest\", rf_search),\n",
    "    (\"XGBoost\", xgb_search),\n",
    "    (\"SVM\", svm_search),\n",
    "    (\"Gaussian Naive Bayes\", gnb_search)\n",
    "]\n",
    "\n",
    "# Run search for each model\n",
    "for model_name, search in model_searches:\n",
    "    print(f\"Testing parameters for {model_name}...\")\n",
    "    search.fit(X_train, y_train)\n",
    "    best_models[model_name] = search.best_estimator_\n",
    "    print(f\"Best parameters for {model_name} complete. [{search.best_params_}] model stored in dictionary.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression performance:\n",
      "\n",
      "Accuracy: 0.8683\n",
      "F1 Score: 0.8706\n",
      "ROC-AUC: 0.8772\n",
      "\n",
      "Misclassification Percentage for Class 0: 15.10%\n",
      "Misclassification Percentage for Class 1: 9.45%\n",
      "\n",
      "--------------------------\n",
      "\n",
      "\n",
      "Random Forest performance:\n",
      "\n",
      "Accuracy: 0.8602\n",
      "F1 Score: 0.8614\n",
      "ROC-AUC: 0.8541\n",
      "\n",
      "Misclassification Percentage for Class 0: 12.65%\n",
      "Misclassification Percentage for Class 1: 16.54%\n",
      "\n",
      "--------------------------\n",
      "\n",
      "\n",
      "XGBoost performance:\n",
      "\n",
      "Accuracy: 0.8522\n",
      "F1 Score: 0.8535\n",
      "ROC-AUC: 0.8460\n",
      "\n",
      "Misclassification Percentage for Class 0: 13.47%\n",
      "Misclassification Percentage for Class 1: 17.32%\n",
      "\n",
      "--------------------------\n",
      "\n",
      "\n",
      "SVM performance:\n",
      "\n",
      "Accuracy: 0.8333\n",
      "F1 Score: 0.8342\n",
      "ROC-AUC: 0.8204\n",
      "\n",
      "Misclassification Percentage for Class 0: 13.88%\n",
      "Misclassification Percentage for Class 1: 22.05%\n",
      "\n",
      "--------------------------\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes performance:\n",
      "\n",
      "Accuracy: 0.8226\n",
      "F1 Score: 0.8271\n",
      "ROC-AUC: 0.8501\n",
      "\n",
      "Misclassification Percentage for Class 0: 23.67%\n",
      "Misclassification Percentage for Class 1: 6.30%\n",
      "\n",
      "--------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def missclass_percent(y_true, y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    misclassification_per_class = {}\n",
    "    for i in range(cm.shape[0]):  # Iterate over each class\n",
    "        total_in_class = cm[i].sum()\n",
    "        if total_in_class > 0:  # Avoid division by zero\n",
    "            misclassified = total_in_class - cm[i, i]\n",
    "            misclassification_percentage_per_class = (misclassified / total_in_class) * 100\n",
    "            misclassification_per_class[i] = misclassification_percentage_per_class\n",
    "\n",
    "    return  misclassification_per_class\n",
    "\n",
    "\n",
    "# Evaluate each optimized model\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    misclassification_per_class = missclass_percent(y_test, y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"\\n{model_name} performance:\\n\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # AUC only available in binary classification\n",
    "    if len(np.unique(y_test)) == 2:\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    print()\n",
    "    for class_label, percentage in misclassification_per_class.items():\n",
    "        print(f\"Misclassification Percentage for Class {class_label}: {percentage:.2f}%\")\n",
    "    \n",
    "    print(\"\\n--------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining best parameters for each model\n",
    "with open('parameters.txt', 'w') as file:\n",
    "    for model_name, params in best_models.items():\n",
    "        file.write(f\"{model_name}: {params}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomics_3-8-20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
