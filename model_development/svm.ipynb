{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supported Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!! Criar csvs limpos para testar depois !!!!!!!!!!!\n",
    "\n",
    "# Base Idea: [link to study](https://pubs.aip.org/aip/acp/article-abstract/2655/1/020103/2888254/Classification-of-normal-and-nodule-lung-images?redirectedFrom=fulltext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code utilizes a Support Vector Machine (SVM) for classification of data extracted from the LIDC-IDRI dataset.\n",
    "\n",
    "The `.csv` file employed in this version contains a **clean and analyzed** dataset derived from the raw data using the `pylidc`, `pyradiomics`, and deep feature extraction methods.\n",
    "\n",
    "The relevant methods can be found in the **csv_cleanup** folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by importing the relevant and necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will convert the three datasets into pandas DataFrames for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_cancer</th>\n",
       "      <th>resnet3d_feature_33</th>\n",
       "      <th>resnet3d_feature_41</th>\n",
       "      <th>resnet3d_feature_52</th>\n",
       "      <th>resnet3d_feature_63</th>\n",
       "      <th>resnet3d_feature_64</th>\n",
       "      <th>resnet3d_feature_66</th>\n",
       "      <th>resnet3d_feature_67</th>\n",
       "      <th>resnet3d_feature_68</th>\n",
       "      <th>resnet3d_feature_72</th>\n",
       "      <th>...</th>\n",
       "      <th>original_firstorder_Median</th>\n",
       "      <th>original_firstorder_Minimum</th>\n",
       "      <th>original_firstorder_RobustMeanAbsoluteDeviation</th>\n",
       "      <th>original_firstorder_Skewness</th>\n",
       "      <th>original_firstorder_Variance</th>\n",
       "      <th>original_gldm_DependenceNonUniformityNormalized</th>\n",
       "      <th>original_glrlm_GrayLevelNonUniformity</th>\n",
       "      <th>original_glrlm_LongRunEmphasis</th>\n",
       "      <th>original_glrlm_RunLengthNonUniformity</th>\n",
       "      <th>original_glrlm_ShortRunEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.339816</td>\n",
       "      <td>0.562524</td>\n",
       "      <td>0.442979</td>\n",
       "      <td>0.730204</td>\n",
       "      <td>0.333658</td>\n",
       "      <td>0.491633</td>\n",
       "      <td>0.398934</td>\n",
       "      <td>0.413691</td>\n",
       "      <td>0.399483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364344</td>\n",
       "      <td>0.011082</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.648394</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.210980</td>\n",
       "      <td>0.878810</td>\n",
       "      <td>0.157930</td>\n",
       "      <td>0.324954</td>\n",
       "      <td>0.496851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526288</td>\n",
       "      <td>0.736178</td>\n",
       "      <td>0.486639</td>\n",
       "      <td>0.796184</td>\n",
       "      <td>0.340574</td>\n",
       "      <td>0.547593</td>\n",
       "      <td>0.475688</td>\n",
       "      <td>0.532664</td>\n",
       "      <td>0.690380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161537</td>\n",
       "      <td>0.034874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359984</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.465737</td>\n",
       "      <td>0.890961</td>\n",
       "      <td>0.364065</td>\n",
       "      <td>0.240920</td>\n",
       "      <td>0.253756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.616598</td>\n",
       "      <td>0.428909</td>\n",
       "      <td>0.104794</td>\n",
       "      <td>0.619367</td>\n",
       "      <td>0.502572</td>\n",
       "      <td>0.125043</td>\n",
       "      <td>0.291206</td>\n",
       "      <td>0.484636</td>\n",
       "      <td>0.376556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224852</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610007</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.448261</td>\n",
       "      <td>0.874003</td>\n",
       "      <td>0.314858</td>\n",
       "      <td>0.249673</td>\n",
       "      <td>0.428741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.395332</td>\n",
       "      <td>0.431717</td>\n",
       "      <td>0.251262</td>\n",
       "      <td>0.735690</td>\n",
       "      <td>0.667631</td>\n",
       "      <td>0.282189</td>\n",
       "      <td>0.237252</td>\n",
       "      <td>0.245101</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368496</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.659629</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.313686</td>\n",
       "      <td>0.804823</td>\n",
       "      <td>0.218568</td>\n",
       "      <td>0.269539</td>\n",
       "      <td>0.537671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.275632</td>\n",
       "      <td>0.454981</td>\n",
       "      <td>0.361014</td>\n",
       "      <td>0.542304</td>\n",
       "      <td>0.659543</td>\n",
       "      <td>0.325105</td>\n",
       "      <td>0.451855</td>\n",
       "      <td>0.178754</td>\n",
       "      <td>0.195805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453218</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.354365</td>\n",
       "      <td>0.870931</td>\n",
       "      <td>0.072326</td>\n",
       "      <td>0.308885</td>\n",
       "      <td>0.574462</td>\n",
       "      <td>0.183526</td>\n",
       "      <td>0.196528</td>\n",
       "      <td>0.378695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_cancer  resnet3d_feature_33  resnet3d_feature_41  resnet3d_feature_52  \\\n",
       "0          1             0.339816             0.562524             0.442979   \n",
       "1          1             0.526288             0.736178             0.486639   \n",
       "2          0             0.616598             0.428909             0.104794   \n",
       "3          1             0.395332             0.431717             0.251262   \n",
       "6          0             0.275632             0.454981             0.361014   \n",
       "\n",
       "   resnet3d_feature_63  resnet3d_feature_64  resnet3d_feature_66  \\\n",
       "0             0.730204             0.333658             0.491633   \n",
       "1             0.796184             0.340574             0.547593   \n",
       "2             0.619367             0.502572             0.125043   \n",
       "3             0.735690             0.667631             0.282189   \n",
       "6             0.542304             0.659543             0.325105   \n",
       "\n",
       "   resnet3d_feature_67  resnet3d_feature_68  resnet3d_feature_72  ...  \\\n",
       "0             0.398934             0.413691             0.399483  ...   \n",
       "1             0.475688             0.532664             0.690380  ...   \n",
       "2             0.291206             0.484636             0.376556  ...   \n",
       "3             0.237252             0.245101             0.460938  ...   \n",
       "6             0.451855             0.178754             0.195805  ...   \n",
       "\n",
       "   original_firstorder_Median  original_firstorder_Minimum  \\\n",
       "0                    0.364344                     0.011082   \n",
       "1                    0.161537                     0.034874   \n",
       "2                    0.224852                     0.000876   \n",
       "3                    0.368496                     0.004530   \n",
       "6                    0.453218                     0.008320   \n",
       "\n",
       "   original_firstorder_RobustMeanAbsoluteDeviation  \\\n",
       "0                                         0.001734   \n",
       "1                                         0.000000   \n",
       "2                                         0.000000   \n",
       "3                                         0.004242   \n",
       "6                                         0.354365   \n",
       "\n",
       "   original_firstorder_Skewness  original_firstorder_Variance  \\\n",
       "0                      0.648394                      0.005157   \n",
       "1                      0.359984                      0.000511   \n",
       "2                      0.610007                      0.002463   \n",
       "3                      0.659629                      0.006736   \n",
       "6                      0.870931                      0.072326   \n",
       "\n",
       "   original_gldm_DependenceNonUniformityNormalized  \\\n",
       "0                                         0.210980   \n",
       "1                                         0.465737   \n",
       "2                                         0.448261   \n",
       "3                                         0.313686   \n",
       "6                                         0.308885   \n",
       "\n",
       "   original_glrlm_GrayLevelNonUniformity  original_glrlm_LongRunEmphasis  \\\n",
       "0                               0.878810                        0.157930   \n",
       "1                               0.890961                        0.364065   \n",
       "2                               0.874003                        0.314858   \n",
       "3                               0.804823                        0.218568   \n",
       "6                               0.574462                        0.183526   \n",
       "\n",
       "   original_glrlm_RunLengthNonUniformity  original_glrlm_ShortRunEmphasis  \n",
       "0                               0.324954                         0.496851  \n",
       "1                               0.240920                         0.253756  \n",
       "2                               0.249673                         0.428741  \n",
       "3                               0.269539                         0.537671  \n",
       "6                               0.196528                         0.378695  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_rfe50.csv')\n",
    "#df = pd.read_csv('semi_clean_cnn.csv')\n",
    "\n",
    "mask = df['is_cancer'] == 1\n",
    "\n",
    "# select all rows except the ones that contain \n",
    "df = df[~mask]\n",
    "\n",
    "# Map 'is_cancer' values from 2 to 1\n",
    "df['is_cancer'] = df['is_cancer'].replace(2, 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Select only columns with floating-point values\n",
    "float_columns = df_encoded.select_dtypes(include='float').columns\n",
    "\n",
    "# Define function to apply one-hot encoding for quantile-based intervals\n",
    "def one_hot_encode_quantile_intervals(column, quantiles):\n",
    "    # Get the quantile boundaries for the column\n",
    "    quantile_values = df_encoded[column].quantile(quantiles).values\n",
    "    \n",
    "    # Create an empty DataFrame to store one-hot encoded columns\n",
    "    encoded_df = pd.DataFrame()\n",
    "    \n",
    "    # Create binary columns for each interval based on quantiles\n",
    "    for i in range(len(quantile_values) - 1):\n",
    "        low = quantile_values[i]\n",
    "        high = quantile_values[i + 1]\n",
    "        encoded_df[f'{column}_interval_{i}'] = df_encoded[column].apply(lambda x: 1 if low <= x < high else 0)\n",
    "    \n",
    "    return encoded_df\n",
    "\n",
    "# Iterate over each floating point column and apply one-hot encoding based on quantile intervals\n",
    "for column in float_columns:\n",
    "    # Define quantiles for dividing the data into intervals\n",
    "    # (You can adjust the quantiles as desired)\n",
    "    quantiles = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "    \n",
    "    # Apply one-hot encoding for this column\n",
    "    encoded_intervals_df = one_hot_encode_quantile_intervals(column, quantiles)\n",
    "    \n",
    "    # Drop the original floating-point column and concatenate the new one-hot encoded columns\n",
    "    df_encoded = df_encoded.drop(columns=[column]).join(encoded_intervals_df)\n",
    "\n",
    "# Now df_encoded contains one-hot encoded columns for each floating-point column based on quantile intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract features (X) and labels (y)\n",
    "# Assume df contains the feature columns and a label column\n",
    "X = df.drop(columns=['is_cancer'])  # Drop the label column to get features\n",
    "y = df['is_cancer']  # Target variable (lung nodule classification)\n",
    "\n",
    "X_enc = df_encoded.drop(columns=['is_cancer'])  # Drop the label column to get features\n",
    "y_enc = df_encoded['is_cancer']  # Target variable (lung nodule classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntarget = \\'is_cancer\\'\\nfeatures = [col for col in df.columns if col != target]\\n\\nimport seaborn as sns\\n\\n# Using seaborn\\'s color palette for a visually distinct color scheme\\nsns.set_palette(\"Set2\")\\n\\n# Setting up a larger figure and adjusting the number of columns for clarity\\nn_cols = 2  # Change number of columns to 2 for easier reading\\nn_rows = (len(features) + 1) // n_cols\\n\\nplt.figure(figsize=(15, 5 * n_rows))\\n\\n# Generate scatter plots with enhancements\\nfor i, feature in enumerate(features):\\n    plt.subplot(n_rows, n_cols, i + 1)\\n    plt.scatter(df[feature], df[target], color=\\'teal\\', alpha=0.6, edgecolor=\\'k\\', s=15)\\n    plt.title(f\\'{feature} vs {target}\\', fontsize=12)\\n    plt.xlabel(feature, fontsize=10)\\n    plt.ylabel(target, fontsize=10)\\n    plt.grid(True, linestyle=\\'--\\', linewidth=0.5, alpha=0.7)\\n\\nplt.tight_layout()\\nplt.show()'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "target = 'is_cancer'\n",
    "features = [col for col in df.columns if col != target]\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Using seaborn's color palette for a visually distinct color scheme\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Setting up a larger figure and adjusting the number of columns for clarity\n",
    "n_cols = 2  # Change number of columns to 2 for easier reading\n",
    "n_rows = (len(features) + 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "\n",
    "# Generate scatter plots with enhancements\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    plt.scatter(df[feature], df[target], color='teal', alpha=0.6, edgecolor='k', s=15)\n",
    "    plt.title(f'{feature} vs {target}', fontsize=12)\n",
    "    plt.xlabel(feature, fontsize=10)\n",
    "    plt.ylabel(target, fontsize=10)\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data preprocessing (scaling)\n",
    "# SVM performs better when features are standardized\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Fit to the data and then transform it\n",
    "\n",
    "X_scaled_enc = scaler.fit_transform(X_enc)  # Fit to the data and then transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Setting up the SVM model\n",
    "# We will use a basic SVM with an RBF kernel (commonly used for medical data)\n",
    "svm_model = SVC(kernel='rbf', C=1, gamma='scale')  # Regularization and kernel hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Performing 10-fold cross-validation\n",
    "# Define KFold with 10 splits\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores for each fold: [0.86290323 0.87096774 0.90322581 0.85483871 0.84677419 0.91129032\n",
      " 0.87096774 0.87903226 0.91056911 0.84552846]\n",
      "Mean accuracy: 0.875609756097561\n",
      "Standard deviation of accuracy: 0.02375285646810462\n",
      "-------------------------------------------------------\n",
      "Cross-validation accuracy scores for each fold: [0.84677419 0.87903226 0.86290323 0.85483871 0.83870968 0.90322581\n",
      " 0.84677419 0.87096774 0.91056911 0.84552846]\n",
      "Mean accuracy: 0.8659323367427222\n",
      "Standard deviation of accuracy: 0.023672582884425888\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation to get the score for each fold\n",
    "cv_scores = cross_val_score(svm_model, X_scaled, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Output the results\n",
    "print(f\"Cross-validation accuracy scores for each fold: {cv_scores}\")\n",
    "print(f\"Mean accuracy: {np.mean(cv_scores)}\")\n",
    "print(f\"Standard deviation of accuracy: {np.std(cv_scores)}\")\n",
    "\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "svm_model = SVC(kernel='rbf', C=0.5, gamma='scale')  # Regularization and kernel hyperparameters\n",
    "cv_scores = cross_val_score(svm_model, X_scaled_enc, y_enc, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Output the results\n",
    "print(f\"Cross-validation accuracy scores for each fold: {cv_scores}\")\n",
    "print(f\"Mean accuracy: {np.mean(cv_scores)}\")\n",
    "print(f\"Standard deviation of accuracy: {np.std(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.87\n",
      "Random Forest Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Rafa\\Anaconda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:02:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.87\n",
      "SVM Accuracy: 0.88\n",
      "Gauss Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=700),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    'SVM': SVC(),\n",
    "    'Gauss': GaussianNB()\n",
    "}\n",
    "\n",
    "# Step 2: Extract features (X) and labels (y)\n",
    "# Assume df contains the feature columns and a label column\n",
    "X = df.drop(columns=['is_cancer'])  # Drop the label column to get features\n",
    "y = df['is_cancer']  # Target variable (lung nodule classification)\n",
    "\n",
    "# Step 3: Data preprocessing (scaling)\n",
    "# SVM performs better when features are standardized\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)  # Fit to the data and then transform it\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{name} Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
